{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ModelFromScratch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOFTxZRejecCE52rTeSOBtn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chevamikado/ImageClassificationCNN/blob/master/ModelFromScratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMpyDsp__qh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Author: Muhammed Zahid Bozkus\n",
        "## Lecture: INF003 - Deep Neural Networks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxXu45pKnSst",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Import Libraries\n",
        "\n",
        "import os\n",
        "import time\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras # Tensorflow high-level api\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from keras import optimizers\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Model, Sequential\n",
        "from keras.models import load_model\n",
        "from keras.layers import Dense,Flatten, GlobalAveragePooling2D, BatchNormalization, Activation, Dropout, Conv2D,MaxPooling2D\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, CSVLogger, ReduceLROnPlateau\n",
        "#from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.applications.xception import Xception\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRKmPJPjnudT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Install the Kaggle API\n",
        "\n",
        "!pip install kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXN-2iBT2PSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Mount the drive to colab notebook\n",
        "\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZjGDZpAn1vm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Upload your Kaggle API Token\n",
        "\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBmvHq-6n2vj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Before importing the dataset we want to use this code\n",
        "## The Kaggle API client expects this file to be in ~/.kaggle\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "## This permissions change avoids a warning on Kaggle tool startup.\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03TqaNNooCh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Download the dataset from Kaggle\n",
        "\n",
        "!kaggle datasets download -d miljan/stanford-dogs-dataset-traintest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCJjj4mjoFbo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Unzip the dataset\n",
        "\n",
        "local_zip = '/content/stanford-dogs-dataset-traintest.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/stanford-dogs')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "to-CpkxcoSDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Paths for the train set and test set\n",
        "\n",
        "train_data_dir = os.path.join(\"/content\", \"stanford-dogs\", \"cropped\", \"train\")\n",
        "test_data_dir = os.path.join(\"/content\", \"stanford-dogs\", \"cropped\", \"test\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yre5FX7K23W7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Specify width-height for images and batch size\n",
        "\n",
        "img_width, img_height = 128, 128\n",
        "batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq4_exUqoy9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Generate batches of tensor image data with real-time data augmentation\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,             \n",
        "        horizontal_flip = True,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        validation_split=0.5 \n",
        "        ##vertical_flip = True,\n",
        "        ##rotation_range=20,\n",
        "        ##shear_range=0.05,           \n",
        "        ##zoom_range=0.2,             \n",
        "        #channel_shift_range=0.1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9i6Rpw8o5EV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Generate bundle of augmented data. In the end we have a generator for the train, validation and test sets. \n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_height, img_width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',    # 2D one-hot encoded labels (batch_size x 101)\n",
        "       )\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "        test_data_dir,\n",
        "        target_size=(img_height, img_width),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',    # 2D one-hot encoded labels (batch_size x 101)\n",
        "        subset='training')\n",
        "test_generator = train_datagen.flow_from_directory(\n",
        "        test_data_dir,\n",
        "        target_size=(img_height, img_width),\n",
        "        batch_size=1,\n",
        "        class_mode='categorical',\n",
        "        subset='validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1ZfQ7mRpoH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Build CNN Architecture\n",
        "\n",
        "model = Sequential()\n",
        "model.add(BatchNormalization(input_shape=(128, 128, 3)))\n",
        "model.add(Conv2D(filters=16, kernel_size=3, kernel_initializer='he_normal', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=3, kernel_initializer='he_normal', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=3, kernel_initializer='he_normal', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=3, kernel_initializer='he_normal', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=3, kernel_initializer='he_normal', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(120, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MsQm8k3XPbl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Convert the Keras model to dot format and save to a file\n",
        "\n",
        "tf.keras.utils.plot_model(\n",
        "    model,\n",
        "    to_file=\"model.png\",\n",
        "    show_shapes=False,\n",
        "    show_layer_names=False,\n",
        "    rankdir=\"LR\",\n",
        "    expand_nested=False,\n",
        "    dpi=96,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_an74uGqU4s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Specify callbacks and start training the model\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='newBestWeights.h5', \n",
        "                               verbose=1, save_best_only=True)\n",
        "\n",
        "history = model.fit_generator(train_generator,\n",
        "          steps_per_epoch = train_generator.n // train_generator.batch_size,\n",
        "          validation_data = validation_generator,\n",
        "          validation_steps = validation_generator.n // validation_generator.batch_size,\n",
        "          epochs = 10,\n",
        "          ##shuffle= True, \n",
        "          callbacks=[checkpointer],        \n",
        "          verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rdGjIYW-jb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Load the saved weights\n",
        "\n",
        "model.load_weights('newBestWeights.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69t-hTEpCQR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Plot accuracy for the train set and validation set\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', \"Validation\"], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1foPqGxCaoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Plot loss for the train set and validation set\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbAkb1ou-y7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Evaluate the model with the test set\n",
        "\n",
        "loss, accuracy = model.evaluate(test_generator)\n",
        "\n",
        "print(\"Test set loss: \", loss)\n",
        "print(\"Test set accuracy: \", accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lwP_lCbxBxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Train model for 10 more epochs\n",
        "\n",
        "history = model.fit_generator(train_generator,\n",
        "          steps_per_epoch = train_generator.n // train_generator.batch_size,\n",
        "          validation_data = validation_generator,\n",
        "          validation_steps = validation_generator.n // validation_generator.batch_size,\n",
        "          epochs = 10,\n",
        "          #shuffle= True, \n",
        "          callbacks=[checkpointer],        \n",
        "          verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeqDdsKbxO1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Evaluate the model again with the test set\n",
        "\n",
        "loss, accuracy = model.evaluate(test_generator)\n",
        "\n",
        "print(\"Test set loss: \", loss)\n",
        "print(\"Test set accuracy: \", accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqXrteUb5nl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}